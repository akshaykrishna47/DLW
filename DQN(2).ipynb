{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFHRB1aX-WM",
        "outputId": "ed56520d-9ef6-4900-c1ea-9f6d3304d4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gymnasium[classic_control]\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting numpy>=1.21.0 (from gymnasium[classic_control])\n",
            "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × pip subprocess to install backend dependencies did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [35 lines of output]\n",
            "      Collecting ninja>=1.8.2\n",
            "        Using cached ninja-1.11.1.1.tar.gz (132 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Building wheels for collected packages: ninja\n",
            "        Building wheel for ninja (pyproject.toml): started\n",
            "        Building wheel for ninja (pyproject.toml): finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        Ã— Building wheel for ninja (pyproject.toml) did not run successfully.\n",
            "        â”‚ exit code: 1\n",
            "        â•°â”€> [13 lines of output]\n",
            "            C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-u22estq2\\overlay\\lib\\python3.10\\site-packages\\setuptools_scm\\git.py:308: UserWarning: git archive did not support describe output\n",
            "              warnings.warn(\"git archive did not support describe output\")\n",
            "            C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-u22estq2\\overlay\\lib\\python3.10\\site-packages\\setuptools_scm\\git.py:327: UserWarning: unprocessed git archival found (no export subst applied)\n",
            "              warnings.warn(\"unprocessed git archival found (no export subst applied)\")\n",
            "            Traceback (most recent call last):\n",
            "              File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-u22estq2\\overlay\\lib\\python3.10\\site-packages\\skbuild\\setuptools_wrap.py\", line 645, in setup\n",
            "                cmkr = cmaker.CMaker(cmake_executable)\n",
            "              File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-u22estq2\\overlay\\lib\\python3.10\\site-packages\\skbuild\\cmaker.py\", line 148, in __init__\n",
            "                self.cmake_version = get_cmake_version(self.cmake_executable)\n",
            "              File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-u22estq2\\overlay\\lib\\python3.10\\site-packages\\skbuild\\cmaker.py\", line 105, in get_cmake_version\n",
            "                raise SKBuildError(msg) from err\n",
            "      \n",
            "            Problem with the CMake installation, aborting build. CMake executable is cmake\n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "        ERROR: Failed building wheel for ninja\n",
            "      Failed to build ninja\n",
            "      ERROR: Could not build wheels for ninja, which is required to install pyproject.toml-based projects\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× pip subprocess to install backend dependencies did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gymnasium[classic_control]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nfXTdmvX-WO"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVIxGsfHX-WO"
      },
      "source": [
        "Goal: Use DQN model to setup optimal temperature for a room <br>\n",
        "\n",
        "Factors affecting initial temperature: <br>\n",
        "<ol>\n",
        "    <li> Room booking status </li>\n",
        "    <li> Outside Temp</li>\n",
        "    <li> Day </li>\n",
        "    <li> Time </li>\n",
        "</ol>\n",
        "\n",
        "Action taken by DQN: <br>\n",
        "<ol>\n",
        "    <li> Increase Temperature </li>\n",
        "    <li> Decrease Temperature   </li>\n",
        "    <li> Maintain Temperature </li>\n",
        "</ol>\n",
        "\n",
        "Rewards for DQN : <br>\n",
        "<ol>\n",
        "    <li> Energy Consumption Levels</li>\n",
        "    <li> User Comfort</li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I89h2gPrX-WP"
      },
      "outputs": [],
      "source": [
        "import gym # OpenAI env\n",
        "import math\n",
        "import random\n",
        "import matplotlib # Plot\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque # Python build-in data structure\n",
        "from itertools import count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EvH-NyNXw28b"
      },
      "outputs": [],
      "source": [
        "# Neural network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeLAkeEP-ot_",
        "outputId": "7990b4c6-c366-461d-930d-79e25166ce0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[29.4, 29.7, 30.0, 29.3, 29.5, 28.6, 29.7, 29.7, 29.6, 28.9, 29.4, 30.6, 29.9, 29.4, 29.7, 30.0, 30.4, 30.8, 29.8, 29.9, 29.9, 29.6, 30.3, 29.4, 30.9, 30.5, 30.1, 30.4, 30.1, 30.9, 30.2, 30.7, 30.6, 29.3, 29.9, 30.1, 30.0, 30.3, 30.7, 30.4, 30.2, 30.9, 30.3, 30.8, 31.5, 29.6, 30.1, 29.7, 30.2, 30.2, 29.3, 29.6, 29.9, 29.9, 30.6, 29.3, 29.7, 30.7, 29.7, 30.0, 30.9, 29.2, 30.4, 29.9, 30.0, 30.3, 30.1, 30.7, 29.4, 30.1, 30.1, 30.6, 31.1, 29.9, 30.9, 30.8, 31.6, 30.2, 31.0, 29.9, 30.5, 30.8, 31.4, 31.4, 30.0, 30.6, 30.7, 30.2, 30.6, 31.1, 29.4, 30.3, 31.0, 30.6, 31.2, 29.8, 30.0, 28.7, 28.0, 27.9, 29.3, 28.7, 29.0, 29.6, 28.8, 28.9, 29.1, 29.0, 29.9, 29.0, 28.1, 28.8, 30.1, 29.4, 29.5, 29.7, 29.3, 29.2, 28.8, 28.9, 27.8, 27.7, 28.9, 27.8, 27.9, 28.5, 28.6, 28.6, 29.0, 27.3, 27.8, 28.4, 28.0, 27.2, 28.6, 28.7, 28.0, 28.0, 28.3, 27.2, 28.7, 28.6, 28.1, 28.4, 29.4, 30.5, 30.6, 30.5, 29.3, 30.4, 30.3, 30.6, 30.7, 29.7, 29.8, 30.2, 30.2, 30.0, 30.4, 29.7, 30.1, 30.8, 30.4, 30.9, 30.0, 30.4, 30.4, 30.3, 31.7, 30.6, 30.6, 30.9, 31.5, 30.9, 31.9, 30.7, 30.5, 30.0, 31.0, 30.8, 30.7, 31.0, 31.0, 32.2, 30.9, 30.2, 30.4, 30.7, 31.7, 30.3, 31.0, 31.0, 28.3, 28.9, 28.6, 29.1, 29.0, 29.9, 29.1, 28.5, 29.0, 30.0, 29.2, 29.5, 29.5, 28.9, 28.4, 28.7, 28.8, 29.6, 29.1, 29.3, 28.4, 29.3, 28.8, 28.7, 31.3, 31.1, 30.6, 31.5, 30.9, 31.0, 30.7, 31.6, 31.9, 31.1, 31.2, 31.5, 31.4, 31.4, 30.7, 31.2, 31.4, 31.0, 30.2, 30.9, 30.4, 29.9, 31.3, 31.6, 30.9, 30.4, 30.4, 30.8, 30.7, 30.5, 30.4, 30.6, 30.3, 29.7, 30.3, 29.8, 30.2, 30.4, 30.9, 30.5, 30.3, 30.9, 29.1, 30.2, 30.6, 30.3, 30.4, 30.0, 29.1, 29.2, 29.8, 29.6, 30.2, 30.7, 29.8, 29.4, 30.2, 30.3, 30.0, 29.8, 30.0, 30.2, 29.6, 30.1, 30.2, 29.0, 31.2, 30.7, 31.0, 29.8, 29.4, 30.1, 28.9, 28.9, 28.9, 27.9, 28.2, 28.7, 28.6, 27.9, 29.0, 29.2, 28.3, 28.3, 28.7, 29.1, 28.8, 28.7, 29.2, 28.5, 29.0, 28.3, 28.1, 28.7, 28.2, 28.9, 28.3, 29.3, 28.8, 28.2, 28.5, 27.9, 28.5, 28.8, 28.8, 29.3, 28.3, 28.1, 28.7, 29.0, 28.9, 29.8, 28.4, 28.0, 28.5, 28.2, 29.4, 28.8, 28.8, 28.2, 29.7, 30.0, 29.9, 30.4, 29.1, 29.4, 29.9, 29.5, 29.5, 29.9, 29.7, 30.3, 30.7, 29.5, 29.3, 30.4, 30.1, 29.6, 30.1, 30.3, 30.4, 28.8, 30.5, 29.4, 30.4, 30.7, 30.8, 30.4, 30.3, 30.5, 30.1, 30.7, 30.8, 29.8, 31.2, 30.1, 30.7, 30.1, 30.6, 30.2, 31.4, 30.7, 30.5, 30.7, 30.8, 30.7, 31.0, 30.2, 31.6, 31.0, 31.0, 31.0, 32.3, 31.1, 31.5, 31.7, 31.6, 31.3, 31.2, 31.5, 31.5, 31.8, 31.0, 32.1, 31.7, 31.5, 31.0, 32.1, 30.9, 31.0, 30.2, 32.3, 30.4, 30.8, 30.5, 29.8, 30.3, 31.2, 31.0, 29.7, 30.1, 29.8, 30.0, 29.8, 29.6, 30.5, 30.1, 30.0, 30.3, 30.5, 30.7, 29.7, 31.1, 28.9, 30.4, 29.8, 31.7, 32.0, 32.5, 32.4, 32.6, 32.3, 31.8, 31.7, 32.4, 32.8, 32.2, 32.3, 32.7, 31.5, 32.3, 32.5, 32.3, 32.7, 32.7, 32.0, 31.4, 31.9, 32.2, 31.3, 30.4, 30.8, 30.2, 30.2, 31.1, 28.8, 30.5, 30.1, 30.0, 30.4, 30.5, 31.0, 29.5, 29.7, 30.3, 30.5, 30.9, 29.5, 29.7, 29.4, 30.0, 29.8, 29.5, 30.0, 31.5, 31.4, 30.5, 32.3, 31.7, 31.2, 30.7, 30.4, 31.1, 31.6, 32.0, 30.8, 30.7, 31.3, 30.7, 30.6, 31.8, 30.9, 32.2, 31.5, 31.9, 30.4, 30.8, 31.0, 27.4, 28.8, 29.4, 28.1, 27.7, 27.2, 28.8, 28.1, 28.2, 29.2, 28.8, 28.9, 28.0, 28.9, 28.4, 28.0, 28.9, 28.7, 29.1, 28.6, 27.7, 29.3, 28.8, 28.0, 30.7, 29.6, 30.9, 31.1, 30.1, 29.6, 31.6, 30.9, 30.7, 31.0, 31.3, 30.4, 30.8, 30.5, 30.4, 30.4, 30.0, 30.5, 30.7, 30.5, 31.5, 30.3, 31.3, 32.2, 29.3, 29.7, 30.3, 29.6, 30.0, 29.4, 30.3, 29.4, 30.3, 29.6, 30.1, 29.3, 29.6, 29.7, 30.5, 29.3, 29.4, 29.6, 29.2, 29.0, 30.1, 30.2, 30.5, 30.0, 29.6, 28.3, 29.2, 29.8, 29.7, 28.3, 29.8, 29.4, 28.7, 29.0, 28.6, 29.2, 29.0, 28.6, 29.0, 29.3, 30.0, 29.9, 28.9, 29.1, 28.1, 29.3, 29.0, 28.7, 30.6, 30.6, 31.2, 31.4, 30.6, 30.6, 30.4, 32.1, 30.1, 30.6, 30.6, 31.6, 31.1, 31.1, 31.2, 31.7, 30.6, 29.5, 31.1, 30.6, 31.8, 30.4, 31.0, 31.0, 30.3, 29.3, 29.3, 29.9, 30.1, 30.1, 29.2, 31.0, 31.0, 29.4, 29.6, 30.5, 30.0, 30.1, 30.6, 29.9, 29.2, 30.2, 28.9, 29.0, 29.7, 31.0, 30.1, 29.8, 29.1, 29.1, 29.1, 29.2, 29.0, 28.9, 28.7, 29.1, 29.9, 30.0, 29.4, 29.5, 29.2, 28.2, 28.6, 29.8, 29.1, 29.6, 29.4, 28.5, 29.3, 29.3, 28.9, 29.8, 30.5, 30.7, 29.9, 29.1, 30.5, 30.8, 29.7, 30.2, 30.6, 30.4, 30.5, 29.9, 30.7, 30.7, 30.4, 29.8, 31.1, 30.2, 30.7, 29.9, 30.1, 31.0, 30.2, 30.5, 31.2, 31.0, 31.9, 30.4, 30.4, 31.0, 32.3, 30.9, 30.3, 31.3, 31.1, 30.6, 31.5, 31.0, 30.5, 31.7, 31.7, 30.5, 31.3, 31.5, 31.1, 31.2, 30.7, 30.7, 28.6, 29.1, 29.1, 29.1, 28.3, 28.5, 27.6, 28.2, 28.7, 28.6, 28.5, 28.7, 29.3, 28.2, 28.6, 29.3, 28.4, 28.9, 29.4, 28.1, 29.1, 28.1, 28.6, 28.9, 30.7, 30.8, 31.5, 30.3, 30.0, 30.2, 30.6, 30.9, 30.1, 30.2, 31.8, 31.6, 30.8, 29.9, 30.4, 30.8, 31.2, 31.1, 31.4, 30.4, 30.3, 31.5, 30.7, 30.1, 29.0, 29.5, 30.2, 28.6, 30.0, 29.6, 29.5, 30.0, 29.8, 29.4, 29.6, 29.9, 30.2, 29.4, 29.5, 30.1, 28.7, 30.4, 29.6, 29.6, 29.0, 29.8, 30.3, 29.5, 30.5, 30.9, 30.7, 30.9, 30.1, 30.5, 30.5, 31.0, 30.6, 30.9, 30.4, 30.9, 30.9, 30.9, 31.6, 30.6, 30.8, 30.1, 31.6, 30.7, 30.3, 29.4, 31.1, 31.8, 31.4, 31.0, 30.5, 31.5, 30.7, 30.5, 31.7, 31.3, 31.9, 30.4, 30.7, 31.0, 31.3, 30.7, 31.5, 31.0, 30.9, 31.0, 31.4, 31.0, 31.3, 31.2, 31.2, 31.0, 29.4, 29.8, 29.3, 28.8, 29.7, 29.7, 29.0, 29.6, 29.2, 29.7, 30.3, 30.2, 29.1, 29.0, 29.4, 29.6, 29.8, 28.9, 29.1, 29.2, 30.4, 28.9, 29.6, 29.8, 29.8, 28.4, 29.3, 30.0, 28.7, 29.8, 29.7, 29.1, 29.1, 29.0, 29.9, 28.7, 29.2, 28.8, 29.7, 29.7, 30.3, 28.7, 29.6, 29.7, 29.4, 29.0, 29.9, 29.5, 28.2, 29.1, 29.0, 28.2, 28.1, 29.0, 28.1, 28.8, 29.2, 28.7, 27.5, 29.2, 29.2, 29.0, 28.8, 29.1, 28.4, 28.8, 28.2, 27.9, 28.5, 27.5, 29.2, 28.4, 28.5, 28.0, 28.0, 27.7, 27.1, 27.8, 27.9, 28.3, 27.3, 28.4, 28.2, 27.7, 28.4, 28.2, 28.0, 28.8, 28.5, 28.0, 27.9, 28.1, 28.0, 29.0, 29.2, 28.1, 30.4, 30.5, 31.3, 31.6, 31.1, 30.0, 30.6, 31.3, 30.4, 30.8, 30.7, 31.6, 31.0, 29.7, 29.5, 31.5, 31.5, 30.7, 30.3, 31.3, 29.6, 30.2, 30.2, 29.9, 31.2, 31.2, 31.0, 31.3, 31.0, 31.7, 30.8, 31.7, 32.5, 31.2, 31.6, 31.4, 30.2, 31.7, 30.7, 31.2, 30.7, 30.8, 31.2, 30.8, 31.0, 30.9, 30.9, 31.4, 31.5, 31.9, 31.4, 30.4, 31.7, 31.4, 30.7, 31.4, 31.5, 31.2, 31.7, 31.6, 32.7, 31.2, 32.5, 30.9, 31.6, 32.6, 31.6, 31.2, 30.6, 31.6, 31.6, 30.9]\n",
            "[21.2, 20.6, 20.0, 21.6, 19.3, 21.3, 22.3, 19.9, 22.0, 19.9, 22.0, 21.5, 19.1, 20.7, 21.7, 21.4, 20.6, 19.9, 20.4, 20.8, 20.1, 19.7, 20.5, 19.6, 21.3, 22.0, 20.5, 20.7, 22.6, 23.1, 23.0, 22.7, 22.3, 22.9, 22.2, 21.8, 21.4, 21.1, 20.6, 21.7, 20.6, 22.5, 22.9, 21.0, 20.6, 21.3, 20.9, 21.4, 22.6, 23.4, 22.4, 23.6, 24.1, 23.7, 25.3, 24.3, 22.8, 22.8, 22.7, 23.7, 22.8, 24.4, 23.9, 24.0, 25.6, 23.0, 25.1, 25.6, 24.2, 24.6, 23.7, 23.4, 24.7, 23.7, 21.3, 22.8, 23.5, 22.0, 23.3, 22.9, 22.7, 22.6, 21.5, 22.6, 20.3, 21.4, 21.5, 22.6, 23.1, 22.7, 23.2, 23.4, 22.0, 22.7, 22.0, 23.3, 21.2, 20.7, 23.5, 22.0, 21.4, 20.8, 23.2, 22.9, 21.9, 21.6, 20.5, 21.8, 23.4, 19.7, 23.0, 22.6, 21.2, 21.0, 21.1, 20.5, 19.8, 21.2, 21.8, 20.8, 24.1, 25.1, 24.1, 24.6, 23.9, 24.4, 26.2, 22.3, 23.1, 23.7, 24.7, 25.0, 24.4, 24.3, 23.3, 24.4, 23.5, 24.3, 26.7, 26.5, 23.6, 24.4, 24.9, 22.0, 20.9, 21.2, 22.6, 22.7, 22.2, 21.6, 20.2, 23.2, 21.1, 21.9, 22.4, 21.6, 21.4, 20.4, 20.7, 21.2, 21.0, 23.1, 22.7, 20.7, 21.7, 22.1, 21.3, 22.3, 22.0, 23.6, 22.3, 21.4, 25.0, 24.0, 22.1, 22.8, 20.2, 22.9, 23.4, 20.3, 23.0, 23.4, 21.9, 22.7, 24.2, 22.8, 21.6, 22.6, 23.7, 22.8, 23.0, 21.2, 25.4, 24.2, 21.9, 24.3, 23.8, 23.4, 22.4, 22.6, 24.2, 23.9, 24.9, 23.4, 23.8, 24.4, 21.8, 22.3, 22.8, 23.2, 23.2, 23.4, 22.1, 23.6, 22.1, 22.9, 21.8, 19.3, 19.9, 22.7, 20.6, 20.7, 24.1, 22.1, 22.4, 22.2, 20.8, 22.0, 21.8, 21.3, 19.3, 22.0, 21.9, 21.1, 20.8, 21.4, 21.4, 21.6, 21.0, 20.6, 17.5, 20.7, 20.5, 17.9, 18.2, 21.6, 18.3, 19.1, 19.2, 19.3, 19.5, 20.0, 20.0, 19.3, 20.9, 20.1, 20.5, 19.5, 19.7, 20.0, 19.8, 19.3, 19.0, 20.2, 24.9, 23.3, 25.6, 23.3, 25.1, 22.7, 24.7, 24.6, 24.0, 25.0, 24.7, 23.6, 26.3, 23.9, 23.9, 24.5, 25.7, 26.6, 23.5, 25.4, 24.6, 23.8, 25.3, 23.7, 16.8, 17.7, 19.2, 16.6, 17.7, 17.4, 19.0, 16.6, 18.3, 21.0, 17.5, 18.5, 18.5, 18.7, 18.6, 18.2, 19.4, 19.0, 16.4, 18.8, 19.2, 18.2, 18.7, 19.2, 22.8, 20.7, 21.8, 22.0, 21.3, 24.2, 22.1, 20.9, 22.0, 21.1, 23.1, 22.7, 21.0, 21.9, 22.5, 21.8, 21.3, 21.1, 22.7, 22.6, 21.2, 24.0, 22.9, 21.2, 20.2, 18.8, 20.3, 21.7, 18.0, 18.9, 20.3, 20.3, 21.0, 19.1, 21.6, 21.0, 21.2, 18.6, 18.6, 20.6, 20.4, 19.7, 22.2, 21.6, 18.6, 20.2, 21.0, 19.7, 24.4, 22.5, 24.2, 22.4, 23.1, 20.7, 24.2, 23.2, 23.1, 22.1, 23.5, 23.1, 24.2, 22.9, 25.5, 22.6, 24.1, 21.9, 24.5, 24.1, 24.0, 21.6, 23.4, 23.6, 21.7, 23.0, 24.0, 22.5, 21.8, 22.0, 22.0, 22.1, 21.0, 21.5, 23.5, 23.8, 23.0, 23.8, 23.2, 21.2, 22.7, 22.3, 22.1, 21.3, 21.7, 21.8, 22.2, 22.9, 23.4, 23.5, 23.1, 25.2, 25.6, 23.0, 24.1, 23.9, 22.2, 24.1, 22.5, 24.7, 24.1, 24.1, 24.7, 24.7, 22.9, 23.9, 23.5, 24.3, 24.5, 23.0, 23.8, 23.5, 22.8, 23.1, 22.3, 20.3, 22.0, 24.5, 25.0, 22.9, 24.3, 24.0, 21.5, 22.5, 22.6, 24.4, 24.7, 23.8, 24.1, 22.9, 22.3, 24.4, 23.8, 21.3, 23.4, 23.3, 24.1, 23.2, 23.9, 24.2, 22.8, 22.3, 22.8, 22.8, 23.0, 24.4, 23.4, 22.7, 22.4, 23.1, 23.7, 23.2, 20.6, 24.2, 24.3, 23.8, 25.8, 24.6, 23.8, 21.1, 24.6, 24.7, 25.0, 25.3, 22.8, 23.8, 24.8, 24.8, 23.1, 24.6, 24.1, 24.5, 25.0, 26.1, 26.9, 25.6, 24.2, 25.6, 25.5, 26.4, 24.9, 25.9, 25.1, 27.9, 20.2, 19.2, 18.6, 18.8, 18.6, 18.5, 18.2, 18.0, 19.9, 17.5, 17.6, 18.2, 17.9, 16.3, 17.9, 19.6, 17.3, 20.2, 18.1, 16.1, 17.5, 17.1, 17.9, 18.0, 21.7, 22.6, 22.7, 21.3, 22.0, 23.2, 22.8, 20.7, 20.7, 21.1, 23.3, 21.2, 22.6, 21.8, 23.0, 22.7, 21.2, 22.7, 24.7, 20.9, 21.7, 21.2, 23.1, 21.5, 26.1, 25.8, 24.1, 23.6, 24.8, 23.8, 25.0, 25.1, 24.1, 25.1, 25.7, 23.6, 25.1, 25.6, 24.9, 25.5, 25.7, 24.9, 24.8, 26.4, 24.1, 24.8, 23.5, 24.0, 22.2, 20.4, 20.2, 19.9, 20.6, 19.6, 19.7, 21.1, 19.4, 19.8, 21.3, 19.9, 21.6, 20.7, 19.1, 18.6, 19.2, 20.5, 24.0, 21.1, 20.4, 20.5, 20.0, 19.2, 23.3, 20.9, 22.5, 24.1, 22.1, 22.1, 22.8, 22.7, 22.7, 23.8, 21.9, 23.1, 22.8, 21.9, 24.3, 21.9, 21.4, 23.5, 21.3, 24.0, 24.5, 23.4, 21.7, 21.9, 20.1, 21.2, 19.2, 19.0, 19.8, 19.3, 20.0, 20.0, 18.4, 20.5, 20.4, 18.7, 19.8, 20.0, 19.8, 22.2, 19.0, 19.6, 19.5, 18.9, 18.0, 19.2, 19.9, 20.9, 23.3, 22.3, 21.9, 20.3, 20.3, 23.2, 21.0, 21.4, 22.1, 21.9, 22.5, 22.9, 22.4, 21.6, 22.2, 22.1, 22.4, 19.7, 21.0, 22.9, 21.5, 20.8, 21.7, 22.7, 25.2, 22.4, 23.0, 25.1, 23.2, 25.6, 24.9, 24.7, 25.1, 23.7, 24.1, 21.8, 23.6, 25.0, 22.2, 24.5, 22.7, 24.4, 24.2, 21.9, 23.5, 24.7, 23.9, 24.3, 22.4, 22.5, 23.2, 23.8, 21.9, 23.8, 22.7, 23.4, 22.8, 22.2, 21.7, 21.8, 22.4, 22.7, 22.5, 23.4, 22.0, 24.3, 22.0, 20.8, 22.4, 23.4, 22.2, 23.9, 22.8, 24.3, 23.5, 24.2, 24.0, 24.1, 24.1, 24.7, 23.0, 22.2, 23.9, 24.6, 23.5, 23.8, 23.6, 23.7, 23.7, 25.4, 24.0, 21.7, 23.0, 23.0, 24.2, 23.7, 22.9, 23.9, 23.8, 22.5, 23.6, 23.6, 23.4, 23.1, 22.7, 23.6, 22.3, 22.5, 23.0, 22.7, 22.7, 24.5, 24.4, 23.4, 21.7, 22.2, 22.0, 23.7, 22.8, 22.5, 18.3, 19.2, 17.2, 20.2, 17.8, 18.6, 18.4, 19.3, 20.2, 18.8, 21.0, 18.5, 20.9, 20.4, 18.5, 18.0, 19.8, 17.8, 20.9, 20.4, 19.8, 19.1, 18.2, 19.2, 24.0, 23.7, 23.4, 23.2, 22.4, 21.9, 22.0, 21.7, 21.7, 23.1, 22.7, 21.1, 20.8, 22.7, 23.3, 22.8, 23.6, 22.0, 21.6, 23.0, 24.6, 21.4, 21.7, 22.9, 20.1, 18.5, 18.3, 20.3, 19.7, 18.5, 18.1, 17.9, 19.8, 16.3, 19.1, 18.1, 18.3, 17.7, 17.2, 19.1, 16.7, 16.1, 18.2, 19.4, 18.0, 19.3, 18.3, 17.2, 20.6, 21.8, 21.9, 22.3, 21.6, 21.8, 20.4, 20.5, 21.4, 23.1, 22.4, 21.4, 21.2, 21.7, 21.6, 22.9, 21.0, 22.2, 22.7, 20.6, 22.4, 22.1, 21.7, 19.4, 20.8, 21.3, 21.7, 21.2, 21.6, 22.4, 22.5, 20.4, 21.4, 21.2, 20.2, 21.4, 23.3, 20.9, 21.9, 20.3, 20.6, 21.1, 21.5, 22.6, 22.0, 20.3, 20.8, 21.6, 18.6, 16.3, 19.8, 17.4, 18.2, 17.7, 18.0, 17.1, 17.6, 18.6, 18.9, 17.7, 17.0, 18.0, 18.3, 18.8, 17.5, 17.4, 18.9, 16.9, 17.5, 17.1, 17.0, 18.0, 21.8, 19.5, 20.8, 21.2, 21.2, 19.4, 21.9, 21.6, 21.7, 21.3, 20.4, 22.0, 21.4, 21.7, 21.0, 22.0, 20.6, 21.1, 23.8, 21.3, 21.9, 22.8, 22.2, 21.1, 24.2, 22.8, 24.7, 21.4, 25.4, 24.8, 25.0, 23.6, 24.8, 23.0, 21.1, 23.5, 23.3, 22.8, 24.4, 22.9, 23.8, 25.8, 22.5, 22.1, 21.8, 23.0, 22.8, 25.4, 20.8, 20.7, 21.4, 22.1, 22.3, 20.4, 21.9, 21.8, 22.9, 21.1, 18.8, 21.2, 21.1, 21.5, 22.4, 21.6, 22.5, 20.9, 22.1, 22.6, 21.3, 22.4, 22.7, 21.6, 22.7, 24.2, 22.8, 22.5, 22.8, 24.8, 21.7, 22.3, 22.9, 22.5, 21.9, 22.2, 22.4, 22.5, 23.2, 23.8, 20.7, 24.4, 22.8, 22.4, 22.9, 23.0, 24.0, 20.3]\n",
            "[1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "headers = ['day_','time_','outside_temp','inside_temp','booking_status',\"energy_consumption\",\"change_in_temp\"]\n",
        "total_data=1008\n",
        "scale=1\n",
        "\n",
        "#generate DAY (first column of data)\n",
        "day_ = []\n",
        "day_in_week = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
        "for i in range(6*scale):\n",
        "    for day in day_in_week:\n",
        "        for j in range(24):\n",
        "            day_.append(day)\n",
        "\n",
        "#generate TIME (second column of data)\n",
        "time_ = []\n",
        "for i in range(6*7*scale):\n",
        "    for j in range(24):\n",
        "        if j%2==1:\n",
        "            time_.append(int(j/2)*100+830)\n",
        "        else:\n",
        "            time_.append(int(j/2)*100+800)\n",
        "\n",
        "import numpy as np\n",
        "#generate OUTSIDE_TEMP (third column of data)\n",
        "outside_temp = []\n",
        "mean = 30\n",
        "std_dev = 1\n",
        "day_temp = np.random.normal(mean, std_dev, size=42*scale)\n",
        "day_temp = np.round(day_temp, decimals=1)\n",
        "for day_mean in day_temp:\n",
        "    for i in range(24):\n",
        "        hour_temp = np.random.normal(day_mean, 0.5)\n",
        "        hour_temp = np.round(hour_temp, decimals=1)\n",
        "        outside_temp.append(hour_temp)\n",
        "print(outside_temp)\n",
        "\n",
        "#generate INSIDE_TEMP (fourth column of data)\n",
        "inside_temp = []\n",
        "mean = 22\n",
        "std_dev = 2\n",
        "inside_day_temp = np.random.normal(mean, std_dev, size=42*scale)\n",
        "inside_day_temp = np.round(inside_day_temp, decimals=1)\n",
        "for inside_day_mean in inside_day_temp:\n",
        "    for i in range(24):\n",
        "        inside_hour_temp = np.random.normal(inside_day_mean, 1)\n",
        "        inside_hour_temp = np.round(inside_hour_temp, decimals=1)\n",
        "        inside_temp.append(inside_hour_temp)\n",
        "print(inside_temp)\n",
        "\n",
        "#generate BOOKING_STATUS (fifth column of data)\n",
        "booking_status = []\n",
        "bernoulli_values = np.random.binomial(n=1, p=0.7, size=24*7)\n",
        "for i in range(6*scale):\n",
        "    for j in range(24*7):\n",
        "        booking_status.append(bernoulli_values[j])\n",
        "print(booking_status)\n",
        "\n",
        "#generate ENERGY_CONSUMPTION (sixth column of data)\n",
        "energy_consumption = []\n",
        "optimal_consumption = 3000\n",
        "for i in range(1008*scale):\n",
        "    hourly_consumption = 3000 + abs(inside_temp[i]-25)*125 + np.random.normal(100, 20)\n",
        "    energy_consumption.append(hourly_consumption)\n",
        "\n",
        "#generate CHANGE_IN_TEMP (seventh column of data)\n",
        "change_in_temp = []\n",
        "for i in range(1008*scale):\n",
        "    if booking_status[i]==0:\n",
        "        change_in_temp.append(0)\n",
        "    elif inside_temp[i]<20:\n",
        "        change_in_temp.append(np.random.randint(0, 4))\n",
        "    elif inside_temp[i]<23:\n",
        "        change_in_temp.append(np.random.randint(-2, 3))\n",
        "    else:\n",
        "        change_in_temp.append(np.random.randint(-2, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "62_00CTJ-ruW"
      },
      "outputs": [],
      "source": [
        "from openpyxl import Workbook\n",
        "\n",
        "# Create a new workbook\n",
        "workbook = Workbook()\n",
        "\n",
        "# Access the active sheet\n",
        "sheet = workbook.active\n",
        "\n",
        "sheet.append(headers)\n",
        "\n",
        "for i in range(1008*scale):\n",
        "    sheet.append([day_[i], time_[i], outside_temp[i], inside_temp[i], booking_status[i], energy_consumption[i], change_in_temp[i]])\n",
        "\n",
        "# Save the workbook\n",
        "workbook.save('output.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnpjZ8k1X-WP",
        "outputId": "84cc1d94-a816-4d3b-8249-4e06173de5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 547.1190668866069\n",
            "Percentage Error: 0.5270235599249095\n"
          ]
        }
      ],
      "source": [
        "# Machine Learning to predict energy consumption\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "training_data = pd.read_excel('output.xlsx')\n",
        "# for day data change mon to 1, tue to 2 etc\n",
        "\n",
        "training_data['day_'] = training_data['day_'].replace(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'],[1,2,3,4,5,6,7])\n",
        "features = ['day_', 'time_', 'outside_temp', 'inside_temp', 'booking_status']\n",
        "X = training_data[features]\n",
        "y = training_data['energy_consumption']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Random forest model to predict energy consumption\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=200, random_state= 50) # 200 trees, random_state for reproducibility\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# percentage error\n",
        "percentage_error = (np.mean(np.abs((y_test - y_pred) / y_test)) * 100)\n",
        "print(f\"Percentage Error: {percentage_error}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODTV4R-dX-WP",
        "outputId": "bc332859-c523-49e2-ec02-a24767f43dda"
      },
      "outputs": [],
      "source": [
        "# Equation to calculate energy consumption\n",
        "def energy_consumption(day, time, outside_temp, inside_temp, booking_status):\n",
        "    day = day\n",
        "    time = time\n",
        "    outside_temp = outside_temp\n",
        "    inside_temp = inside_temp\n",
        "    booking_status = booking_status\n",
        "    energy_consumption = rf_model.predict([[day, time, outside_temp, inside_temp, booking_status]])\n",
        "    return energy_consumption\n",
        "\n",
        "def user_comfort(outside_temp, inside_temp, booking_status):\n",
        "    if(booking_status == 0):\n",
        "        change_in_temp = 0\n",
        "    elif(booking_status == 1):\n",
        "        if(outside_temp < 25): #cold weather\n",
        "            if (inside_temp < 20):\n",
        "                change_in_temp = np.random.randint(0, 6)\n",
        "            elif (inside_temp < 23):\n",
        "                change_in_temp = np.random.randint(0,3)\n",
        "            else:\n",
        "                change_in_temp = np.random.randint(-2, 1)\n",
        "        else: #hot weather\n",
        "            if (inside_temp < 20):\n",
        "                change_in_temp = np.random.randint(0, 2)\n",
        "            elif (inside_temp < 23):\n",
        "                change_in_temp = np.random.randint(-2, 3)\n",
        "            else:\n",
        "                change_in_temp = np.random.randint(-5, 3)\n",
        "    new_temp = inside_temp + change_in_temp\n",
        "    return new_temp\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "HY95Te_9X-WP"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "import random\n",
        "\n",
        "class ThermostatEnvironment(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(ThermostatEnvironment, self).__init__()\n",
        "        self.day = 1\n",
        "        self.time = 1\n",
        "        self.booking_status = 0\n",
        "        self.machine_temp = 18\n",
        "        self.outside_temp = random.randint(23, 40)\n",
        "        self.actual_temp = user_comfort(self.outside_temp, self.machine_temp, self.booking_status)\n",
        "        self.action_space = spaces.Discrete(3)  # Increase, Decrease, Maintain\n",
        "        self.observation_space = spaces.Box(low=np.array([1, 1, 0, 23, 18]), high=np.array([5, 24, 1, 40, 25]), dtype=np.float32)\n",
        "        self.max_temp = 25\n",
        "        self.min_temp = 18\n",
        "        self.reward = 0\n",
        "        self.done = False\n",
        "    \n",
        "    \n",
        "    def update_environment(self, time, day):\n",
        "            if time == 24:\n",
        "                time = 1\n",
        "                if day == 7:\n",
        "                    day = 8\n",
        "                else:\n",
        "                    day += 1\n",
        "            else:\n",
        "                time += 1\n",
        "            return time, day, random.randint(0, 1), random.randint(23, 40)\n",
        "\n",
        "    def step(self, action):\n",
        "        \n",
        "        # Action logic\n",
        "        if action == 0: # Increase temperature\n",
        "            self.machine_temp += 1\n",
        "        elif action == 2: # Decrease temperature\n",
        "            self.machine_temp -= 1\n",
        "        else: # Maintain temperature\n",
        "            pass\n",
        "\n",
        "        \n",
        "\n",
        "        # Ensure temperature is within bounds\n",
        "        self.machine_temp = np.clip(self.machine_temp, self.min_temp, self.max_temp)\n",
        "\n",
        "        # Calculate energy consumption\n",
        "        energy = energy_consumption(self.day, self.time, self.outside_temp, self.actual_temp, self.booking_status)\n",
        "\n",
        "        # Calculate reward\n",
        "        # Adjust the energy_reward calculation\n",
        "        energy_reward = -((energy - 3200) / 3200)**2  # Quadratic penalty for deviation\n",
        "\n",
        "        # Introduce a threshold for acceptable energy consumption\n",
        "        acceptable_energy_threshold = 3200\n",
        "        if energy <= acceptable_energy_threshold:\n",
        "            energy_reward += 0.2\n",
        "        #print(f\"Energy Reward: {energy_reward}\")\n",
        "\n",
        "        # Modify the comfort_reward calculation\n",
        "        temperature_range_penalty = 0.1  # Adjust based on your criteria\n",
        "        comfort_reward = temperature_range_penalty * (self.actual_temp - self.machine_temp)**2\n",
        "\n",
        "        #print(f\"Comfort Reward: {comfort_reward}\")\n",
        "\n",
        "        # Adjust the weights and introduce a trade-off factor\n",
        "        trade_off_factor = 0.4  # Adjust based on your desired trade-off\n",
        "        reward = (1 - trade_off_factor) * energy_reward + trade_off_factor * comfort_reward\n",
        "        #print(f\"Total Reward: {reward}\")\n",
        "\n",
        "        self.reward += reward\n",
        "        self.time, self.day, self.booking_status, self.outside_temp = self.update_environment(self.time, self.day)\n",
        "        if self.day == 8:\n",
        "            self.done = True\n",
        "\n",
        "        return np.array([self.day, self.time, self.booking_status, self.outside_temp, self.actual_temp]), reward, self.done, {}\n",
        "\n",
        "    \n",
        "    def reset(self):\n",
        "        self.day = 1\n",
        "        self.time = 1\n",
        "        self.booking_status = 0\n",
        "        self.outside_temp = 30\n",
        "        self.machine_temp = 18 # temp set by machine\n",
        "        self.actual_temp = user_comfort(self.outside_temp, self.machine_temp, self.booking_status)\n",
        "        self.done = False\n",
        "        return np.array([self.day, self.time, self.booking_status, self.outside_temp, self.actual_temp])\n",
        "\n",
        "    def render(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2un0_wSX-WQ"
      },
      "source": [
        "# Q Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oMdGch4pX-WQ"
      },
      "outputs": [],
      "source": [
        "# Neural Network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import copy\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 25)  # 5 input features, 1 output features\n",
        "        self.fc2 = nn.Linear(25,25)\n",
        "        self.fc3 = nn.Linear(25, action_size) # 10 input features, 2 output features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "WutdFIfXX-WQ"
      },
      "outputs": [],
      "source": [
        "# memory\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "\n",
        "    def push(self, state, action, next_state, reward):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append((state, action, next_state, reward))\n",
        "        else:\n",
        "            self.memory.pop(0)\n",
        "            self.memory.append((state, action, next_state, reward))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt23v4heX-WQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTtV3I3CX-WQ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y7JGqacX-WQ",
        "outputId": "a59314ac-1e30-45d3-e8ec-2c985511c974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "gamma = 0.99\n",
        "buffer_limit = 100000\n",
        "batch_size = 64\n",
        "tau = 0.0005\n",
        "input_size = 5\n",
        "action_size = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the environment\n",
        "env = ThermostatEnvironment()\n",
        "env.reset()\n",
        "\n",
        "# Initialize the model\n",
        "model = DQN(input_size, action_size).to(device)\n",
        "target_model = copy.deepcopy(model)\n",
        "target_model.load_state_dict(model.state_dict())\n",
        "target_model.eval()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Initialize the replay buffer\n",
        "replay_buffer = []\n",
        "replay_buffer_size = 0\n",
        "\n",
        "# Initialize the training parameters\n",
        "if torch.cuda.is_available():\n",
        "    print('Using GPU')\n",
        "    num_episodes = 50\n",
        "else:\n",
        "    print('Using CPU')\n",
        "    num_episodes = 50\n",
        "epsilon = 0.1\n",
        "epsilon_decay = 0.99\n",
        "epsilon_min = 0.01\n",
        "update_every = 10\n",
        "update_count = 0\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "# Get number of states from gym observation space\n",
        "state,info = env.reset(),{}\n",
        "n_states = len(state)\n",
        "\n",
        "policy_net = DQN(n_states, n_actions).to(device)\n",
        "target_net = DQN(n_states, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=0.01)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "def select_action(state, epsilon):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = epsilon\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
        "\n",
        "episodes_duration = []\n",
        "\n",
        "def optimize_model():\n",
        "    if len(memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    # Sample a batch from the replay memory\n",
        "    batch = memory.sample(batch_size)\n",
        "\n",
        "    # Unpack the batch\n",
        "    state_batch, action_batch, next_state_batch, reward_batch = map(torch.cat, zip(*batch))\n",
        "    action_batch = action_batch.view(-1, 1).long()\n",
        "\n",
        "    # Compute Q-values for the current state-action pairs\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute Q-values for the next state and find the maximum\n",
        "    next_state_values = target_net(next_state_batch).max(1)[0].detach()\n",
        "\n",
        "    # Compute the expected Q-values using the Bellman equation\n",
        "    expected_state_action_values = (next_state_values * gamma) + reward_batch\n",
        "\n",
        "    # Calculate the Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JZ70GN45X-WR",
        "outputId": "8e75e359-440f-4cfb-9e9d-056cff972e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, Total Reward: 235.58400268829428, Loss: 0.22972726821899414\n",
            "Episode 1, Total Reward: 48.46985745313577, Loss: 0.2891072928905487\n",
            "Episode 2, Total Reward: 101.65478898375295, Loss: 0.3357812166213989\n",
            "Episode 3, Total Reward: 144.31324136001058, Loss: 0.2841682434082031\n",
            "Episode 4, Total Reward: 182.60543409199454, Loss: 0.3607337176799774\n",
            "Episode 5, Total Reward: 105.25424717832357, Loss: 0.3332667350769043\n",
            "Episode 6, Total Reward: 156.33772905077785, Loss: 0.3375297486782074\n",
            "Episode 7, Total Reward: 143.3136581988074, Loss: 0.3189809322357178\n",
            "Episode 8, Total Reward: 131.42110708309337, Loss: 0.33634069561958313\n",
            "Episode 9, Total Reward: 140.24393807910383, Loss: 0.2563375234603882\n",
            "Episode 10, Total Reward: 128.50845451140776, Loss: 0.3037267327308655\n",
            "Episode 11, Total Reward: 118.92200854164548, Loss: 0.33125370740890503\n",
            "Episode 12, Total Reward: 173.04250290757045, Loss: 0.32361549139022827\n",
            "Episode 13, Total Reward: 126.65314506390132, Loss: 0.3462395668029785\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "episode_rewards = []\n",
        "episode_losses = []\n",
        "episodes_duration = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    state = torch.tensor([state], device=device, dtype=torch.float32)\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, _ = env.step(action.item())\n",
        "        next_state = torch.tensor([next_state], device=device, dtype=torch.float32)\n",
        "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
        "        memory.push(state, action, next_state, reward)\n",
        "        state = next_state\n",
        "        total_reward += reward.item()\n",
        "        loss = optimize_model()\n",
        "        steps += 1\n",
        "\n",
        "    # Check if loss is not None before accessing 'item'\n",
        "    if loss is not None:\n",
        "        episode_losses.append(loss.item())\n",
        "\n",
        "    episode_rewards.append(total_reward)\n",
        "    episodes_duration.append(steps)\n",
        "\n",
        "    print(f\"Episode {episode}, Total Reward: {total_reward}, Loss: {loss}\")\n",
        "\n",
        "    if episode % update_every == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "\n",
        "# Plot total rewards and losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the total rewards\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Reward over Episodes')\n",
        "\n",
        "# Plot the losses\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(episode_losses)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Episodes')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot the duration of each episode\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(episodes_duration)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Duration')\n",
        "plt.title('Episode Duration')\n",
        "plt.show()\n",
        "\n",
        "# do not print warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
